{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Ym50e7ijHI"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I3XPSk6ijHJ",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "!pip install unsloth\n",
        "!pip install transformers==4.55.4\n",
        "!pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xLDGk41C7IF"
      },
      "source": [
        "### Model Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "8e1804ea6f5b486e9f933cbfa4ee75a4",
            "b94924121ab142cd94711888282dc5e7",
            "f183d9d93b0b4d4196522043152a82db",
            "04aeb49804ef4fe9b8064fbcdb905709",
            "91bb034cb9a449fca2ea69a9e2fdda90",
            "27ba5e5b74034507a3585e708f5764cd",
            "c0bcab7a3d094532a267f68d8441eb2d",
            "1bdc4953166e4b34ba1f394b01442ab5",
            "01d0eabca0154c1aa0dbc025a3dcedf7",
            "9af47aa12e7c484390aec580ce79e563",
            "21351ab92db34c2da5769b7623088bdf",
            "174206da79cb4f6a95d9f4357f8cb26b",
            "d66d2a7222824faab9f4ae0d88cadad2",
            "f56191075ac8481f84fae1e984edc111",
            "25d16b661431427a8cccba3d11a68d4c",
            "2512cb5c934c48b6b1734ab323a81f0e",
            "508671cf4b0d4c3d966e1f8ba8e977f4",
            "43d0c8b66ffa4ac2a8267ffe8b56c96f",
            "cd010321d0fe42d180f0650ba07b41f2",
            "86eb3da0e574405daf1ea6f7cbb841e8",
            "781d2fe76a674391b0062964936544be",
            "bc071f665b4d4231bd2c124ff92645d5"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "067acb4f-9450-4d38-d4f3-193f400d76ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.12.8: Fast Qwen2_5_Vl patching. Transformers: 4.55.4.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/6.90G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8e1804ea6f5b486e9f933cbfa4ee75a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "174206da79cb4f6a95d9f4357f8cb26b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastVisionModel\n",
        "import torch\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"unsloth/Qwen2.5-VL-7B-Instruct-bnb-4bit\",\n",
        "    load_in_4bit = True,\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZsfBuZDeCL"
      },
      "outputs": [],
      "source": [
        "model = FastVisionModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = True,\n",
        "    finetune_language_layers   = True,\n",
        "    finetune_attention_modules = True,\n",
        "    finetune_mlp_modules       = True,\n",
        "    r = 16,\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0,\n",
        "    bias = \"none\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "7ad707c833c24956a41521131aed41f5",
            "8bba5c634a0c448a959cbb40eac5a219",
            "edfe16024bf242cc89d2fa4c02179cdb",
            "43076e5b8c0d46adbe50a3163a19ff0e",
            "509917d6a25c4d69b2503edf7ba87113",
            "190e7de81a3041afb60f5af19c78e6d2",
            "5dd6820176ef47b397144159baf5246e",
            "c093966ca6fb485b93ab513790c08e77",
            "2d5586aba8174e3c89d9e85892a54365",
            "625625d0f2144a9b8570213ef04ca288",
            "b4efb07ef6f948b3b65d9c9c309cc6f9"
          ]
        },
        "id": "ofHO-rY31xgr",
        "outputId": "640c8656-31de-4065-883c-c7fe64734561"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad707c833c24956a41521131aed41f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['img_id', 'image', 'mask', 'width', 'height', 'label'],\n",
            "        num_rows: 4220\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "!!for i in {0..4}; do wget -q https://huggingface.co/datasets/saberzl/SID_Set/resolve/main/data/train-$(printf \"%05d\" $i)-of-00249.parquet; done\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "file_names = [f\"train-{i:05d}-of-00249.parquet\" for i in range(5)]\n",
        "\n",
        "# ['train-00000-of-00249.parquet', 'train-00001-of-00249.parquet', 'train-00002-of-00249.parquet', 'train-00003-of-00249.parquet', 'train-00004-of-00249.parquet']\n",
        "\n",
        "dataset = load_dataset(\"parquet\", data_files=file_names)\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDcMcwzJzssT"
      },
      "outputs": [],
      "source": [
        "train_dataset = dataset[\"train\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ra2E1Wlqac4"
      },
      "outputs": [],
      "source": [
        "# remove images with label 2\n",
        "dataset_no_label_2 = train_dataset.filter(lambda example: example['label'] != 2, num_proc=12)\n",
        "\n",
        "# choose only images with width 1024\n",
        "dataset_1024_only = dataset_no_label_2.filter(lambda example: example['width'] == 1024, num_proc=12)\n",
        "\n",
        "\n",
        "dataset_0_1024 = dataset_1024_only.filter(lambda e: e['label'] == 0,  num_proc=12)\n",
        "dataset_1_1024 = dataset_1024_only.filter(lambda e: e['label'] == 1,  num_proc=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEabehDJsIeb"
      },
      "outputs": [],
      "source": [
        "# undersample label 1 to match label 0 count\n",
        "dataset_label_1_undersampled = dataset_1_1024.select(\n",
        "    range(len(dataset_1_1024)),\n",
        ").shuffle(seed=42).select(range(1134))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II5LsDrisprk"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "dataset_dengelenmis_final = concatenate_datasets([\n",
        "    dataset_0_1024,                   # 1134 item\n",
        "    dataset_label_1_undersampled       # 1134 item\n",
        "])\n",
        "\n",
        "# shuffle dataset for better training\n",
        "dataset_dengelenmis_final = dataset_dengelenmis_final.shuffle(seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import ClassLabel, Features, Value\n",
        "\n",
        "# convert label colon to ClassLabel to work with\n",
        "yeni_ozellikler = dataset_dengelenmis_final.features.copy()\n",
        "yeni_ozellikler[\"label\"] = ClassLabel(num_classes=2)\n",
        "dataset_dengelenmis_final = dataset_dengelenmis_final.cast(yeni_ozellikler)\n",
        "\n",
        "\n",
        "#%70 Train, %15 Validation, %15 Test\n",
        "bolunmus_dataset = dataset_dengelenmis_final.train_test_split(\n",
        "    test_size=0.3,\n",
        "    seed=42,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "\n",
        "train_dataset = bolunmus_dataset[\"train\"]\n",
        "temp_dataset = bolunmus_dataset[\"test\"]\n",
        "\n",
        "\n",
        "ikinci_bolme = temp_dataset.train_test_split(\n",
        "    test_size=0.5,\n",
        "    seed=42,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "\n",
        "validation_dataset = ikinci_bolme[\"train\"]\n",
        "test_dataset = ikinci_bolme[\"test\"]"
      ],
      "metadata": {
        "id": "l6oTVru6C4gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXzJZzHEgXe"
      },
      "outputs": [],
      "source": [
        "# convert dataset to proper format for LLM\n",
        "instruction = \"\"\"Real/Fake?\"\"\"\n",
        "def convert_to_conversation(sample):\n",
        "    label_text = \"Real\" if sample[\"label\"] == 0 else \"Fake\"\n",
        "    conversation = [\n",
        "        { \"role\": \"user\",\n",
        "          \"content\" : [\n",
        "            {\"type\" : \"text\",  \"text\"  : instruction},\n",
        "            {\"type\" : \"image\", \"image\" : sample[\"image\"]} ]\n",
        "        },\n",
        "        { \"role\" : \"assistant\",\n",
        "          \"content\" : [\n",
        "            {\"type\" : \"text\",  \"text\"  : label_text } ]\n",
        "        },\n",
        "    ]\n",
        "    return { \"messages\" : conversation }\n",
        "converted_dataset = [convert_to_conversation(sample) for sample in train_dataset]\n",
        "converted_dataset_valid = [convert_to_conversation(sample) for sample in validation_dataset]\n",
        "converted_dataset_test = [convert_to_conversation(sample) for sample in test_dataset]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahVyzSPquawh"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyLqn0aQskyi"
      },
      "outputs": [],
      "source": [
        "from transformers import EvalPrediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pdb as pd\n",
        "\n",
        "# required token ids, end of message, \"Fake\" text token, \"Real\" text token\n",
        "END_OF_MESSAGE_ID = 151645 # <|im_end|>\n",
        "FAKE_ID = 52317\n",
        "REAL_ID = 12768\n",
        "CRITICAL_IDS = {FAKE_ID, REAL_ID}\n",
        "\n",
        "\n",
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    # this runs after each batch\n",
        "\n",
        "    if isinstance(logits, tuple):\n",
        "        logits = logits[0]\n",
        "\n",
        "    return logits.argmax(dim=-1)  # (batch, seq_len, vocab) -> (batch, seq_len)\n",
        "\n",
        "def compute_classification_metrics(p: EvalPrediction):\n",
        "    \"\"\"\n",
        "    Predictions zaten argmax'lanmÄ±ÅŸ geliyor (preprocess_logits_for_metrics sayesinde)\n",
        "    \"\"\"\n",
        "\n",
        "    # use tensor\n",
        "    preds = torch.from_numpy(p.predictions)\n",
        "    labels_tensor = torch.from_numpy(p.label_ids)\n",
        "\n",
        "    # apply mask to remove unnecessary token\n",
        "    mask = labels_tensor != -100\n",
        "\n",
        "    # find the token before last token with id \"151645\"(im_end)\n",
        "    def find_decision_token(token_seq, seq_mask):\n",
        "        # find decision token using mask\n",
        "\n",
        "        # choose unmasked tokens\n",
        "        masked_seq = token_seq[seq_mask]\n",
        "\n",
        "        indices_of_end_token = (masked_seq == END_OF_MESSAGE_ID).nonzero(as_tuple=True)[0]\n",
        "\n",
        "        if indices_of_end_token.size(0) > 0:\n",
        "            last_end_token_index = indices_of_end_token[-1]\n",
        "            karar_index = last_end_token_index - 1\n",
        "\n",
        "            if karar_index >= 0:\n",
        "                return masked_seq[karar_index]\n",
        "        return None\n",
        "\n",
        "    final_preds_list = []\n",
        "    final_labels_list = []\n",
        "\n",
        "    # run on each item\n",
        "    for i in range(preds.size(0)):\n",
        "        seq_mask = mask[i]\n",
        "\n",
        "        label_token = find_decision_token(labels_tensor[i], seq_mask)\n",
        "        pred_token = find_decision_token(preds[i], seq_mask)\n",
        "\n",
        "        # compare tokens\n",
        "        if label_token is not None and label_token.item() in CRITICAL_IDS:\n",
        "            if pred_token is not None:\n",
        "                final_labels_list.append(label_token.item())\n",
        "                final_preds_list.append(pred_token.item())\n",
        "            else:\n",
        "                final_labels_list.append(label_token.item())\n",
        "                final_preds_list.append(-999)\n",
        "\n",
        "    if not final_labels_list:\n",
        "        return {\"accuracy\": 0.0, \"eval_RealFake_count\": 0}\n",
        "\n",
        "    accuracy = accuracy_score(final_labels_list, final_preds_list)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"eval_RealFake_count\": int(len(final_labels_list))\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95_Nn-89DhsL",
        "outputId": "505eb3a5-8698-4513-8d74-c9406517c58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Model does not have a default image size - using 512\n"
          ]
        }
      ],
      "source": [
        "from unsloth.trainer import UnslothVisionDataCollator\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "FastVisionModel.for_training(model)\n",
        "early_stopping = EarlyStoppingCallback(\n",
        "    early_stopping_patience=3,\n",
        "    early_stopping_threshold=0.0,\n",
        ")\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    data_collator = UnslothVisionDataCollator(model, tokenizer),\n",
        "    train_dataset = converted_dataset,\n",
        "    eval_dataset = converted_dataset_valid,\n",
        "    callbacks = [early_stopping],\n",
        "    compute_metrics = compute_classification_metrics,\n",
        "    preprocess_logits_for_metrics = preprocess_logits_for_metrics,\n",
        "    args = SFTConfig(\n",
        "        per_device_train_batch_size = 8,\n",
        "        per_device_eval_batch_size = 10,\n",
        "        gradient_accumulation_steps = 5,\n",
        "        warmup_ratio = 0.1,\n",
        "        num_train_epochs = 1,\n",
        "        learning_rate = 1e-4,\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\",\n",
        "        eval_steps = 10,\n",
        "        metric_for_best_model = \"accuracy\",\n",
        "        eval_strategy=\"steps\",\n",
        "        load_best_model_at_end = True,\n",
        "        remove_unused_columns = False,\n",
        "        dataset_text_field = \"\",\n",
        "        dataset_kwargs = {\"skip_prepare_dataset\": True},\n",
        "        max_length = 2048,\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCqI0J-E4jw0"
      },
      "source": [
        "### Inference Tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACGPFn0O9e9W"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pdb\n",
        "FastVisionModel.for_inference(model)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "actual_tokenizer = tokenizer.tokenizer\n",
        "\n",
        "# Get token IDs for \"Fake\" and \"Real\"\n",
        "fake_token_id = actual_tokenizer.encode(\"Fake\", add_special_tokens=False)[0]\n",
        "real_token_id = actual_tokenizer.encode(\"Real\", add_special_tokens=False)[0]\n",
        "\n",
        "\n",
        "for num in range(len(converted_dataset_test)):\n",
        "    image = converted_dataset_test[num]['messages'][0]['content'][1]['image']\n",
        "    act_label = converted_dataset_test[num]['messages'][1]['content'][0]['text']\n",
        "\n",
        "    instruction = \"\"\"Real/Fake?\"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": [\n",
        "            {\"type\": \"image\"},\n",
        "            {\"type\": \"text\", \"text\": instruction}\n",
        "        ]}\n",
        "    ]\n",
        "\n",
        "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "    inputs = tokenizer(\n",
        "        image,\n",
        "        input_text,\n",
        "        add_special_tokens=False,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Generate to get prediction with scores\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128,\n",
        "                            do_sample=False,\n",
        "                            output_scores=True, return_dict_in_generate=True)\n",
        "\n",
        "    generated_ids = outputs.sequences[0][inputs['input_ids'].shape[1]:]\n",
        "    generated_text = actual_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "    prediction = generated_text.strip().split()[0].lower() if generated_text.strip() else \"\"\n",
        "    print(generated_text)\n",
        "\n",
        "    # Get probabilities for the first token (Fake or Real)\n",
        "    first_token_logits = outputs.scores[0][0]  # [vocab_size]\n",
        "    probabilities = F.softmax(first_token_logits, dim=-1)\n",
        "\n",
        "    fake_prob = probabilities[fake_token_id].item() * 100\n",
        "    real_prob = probabilities[real_token_id].item() * 100\n",
        "\n",
        "    actual = act_label.lower().strip()\n",
        "\n",
        "    pred_prob = fake_prob if prediction == \"fake\" else real_prob\n",
        "\n",
        "    is_correct = prediction == actual\n",
        "    if is_correct:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "\n",
        "    status = \"âœ… CORRECT\" if is_correct else \"âŒ INCORRECT\"\n",
        "    print(f\" {num+1}/{len(converted_dataset_valid)}: {status}\")\n",
        "    print(f\"  {act_label} | {prediction} ({pred_prob:.2f}%)\")\n",
        "    print(f\"CORRECT/TOTAL PREDICTION {correct}/{total} ({100*correct/total:.2f}%)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(f\"FINAL ACCURACY: {correct}/{total} = {100*correct/total:.2f}%\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf3kzGKjfuPi"
      },
      "source": [
        "### Other Datasets Testing (ImageNet and Dalle3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUEAoSo8f0gF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/Cv/dalle3_random_100\"\n",
        "valid_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
        "\n",
        "def get_label_from_filename(filename):\n",
        "    return \"fake\"\n",
        "\n",
        "image_files = []\n",
        "if os.path.exists(dataset_path):\n",
        "    for filename in os.listdir(dataset_path):\n",
        "        ext = os.path.splitext(filename)[1].lower()\n",
        "        if ext in valid_extensions:\n",
        "            image_files.append(os.path.join(dataset_path, filename))\n",
        "else:\n",
        "    print(f\"No folder found!\")\n",
        "\n",
        "if len(image_files) > 0:\n",
        "    print(f\"Total images: {len(image_files)}. Starting..\\n\")\n",
        "\n",
        "    actual_tokenizer = tokenizer.tokenizer\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for img_path in image_files:\n",
        "        filename = os.path.basename(img_path)\n",
        "        true_label = get_label_from_filename(filename)\n",
        "\n",
        "        if true_label is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            instruction = \"Real/Fake?\"\n",
        "            messages = [\n",
        "                {\"role\": \"user\", \"content\": [\n",
        "                    {\"type\": \"image\"},\n",
        "                    {\"type\": \"text\", \"text\": instruction}\n",
        "                ]}\n",
        "            ]\n",
        "            input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
        "            inputs = tokenizer(\n",
        "                image,\n",
        "                input_text,\n",
        "                add_special_tokens=False,\n",
        "                return_tensors=\"pt\",\n",
        "            ).to(\"cuda\")\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(**inputs, max_new_tokens=5,\n",
        "                                        use_cache=True, do_sample=False,\n",
        "                                        output_scores=True, return_dict_in_generate=True)\n",
        "\n",
        "            generated_ids = outputs.sequences[0][inputs['input_ids'].shape[1]:]\n",
        "            generated_text = actual_tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
        "            raw_pred = generated_text.strip().split()[0].lower() if generated_text.strip() else \"unknown\"\n",
        "\n",
        "            if \"fake\" in raw_pred:\n",
        "                prediction = \"fake\"\n",
        "            elif \"real\" in raw_pred:\n",
        "                prediction = \"real\"\n",
        "            else:\n",
        "                prediction = \"unknown\"\n",
        "\n",
        "            y_true.append(true_label)\n",
        "            y_pred.append(prediction)\n",
        "\n",
        "            match_icon = \"âœ…\" if true_label == prediction else \"âŒ\"\n",
        "            print(f\"{match_icon} {filename} | True: {true_label} -> Pred: {prediction.upper()}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception!!! {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"RESULTS\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    if len(y_true) > 0:\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        print(f\"\\nAccuracy: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "\n",
        "        labels = [\"fake\", \"real\"]\n",
        "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "        cm_df = pd.DataFrame(cm, index=[f\"Actual {l}\" for l in labels],\n",
        "                             columns=[f\"Pred {l}\" for l in labels])\n",
        "\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(cm_df)\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_true, y_pred, target_names=labels))\n",
        "    else:\n",
        "        print(\"No data!\")\n",
        "\n",
        "else:\n",
        "    print(\"No data in folder! Check path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "e3775863-afa8-4ba2-a9d4-e7e1c9005551"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.save_pretrained(\"fake_image_detector_99\")\n",
        "tokenizer.save_pretrained(\"fake_image_detector_99\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "collapsed_sections": [
        "y4Ym50e7ijHI",
        "9xLDGk41C7IF",
        "vITh0KVJ10qX",
        "ahVyzSPquawh",
        "XCqI0J-E4jw0",
        "Bf3kzGKjfuPi"
      ]
    },
    "kernelspec": {
      "display_name": "Python3 (System)",
      "language": "python",
      "name": "system-python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}